{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceTracking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15KyKbqPMPgKBtwXGW3pmh4Ok2sHqC6IV",
      "authorship_tag": "ABX9TyOnnP4Q/49UZwIC9AbnUcKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naenumtou/statisticalModel/blob/main/faceTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nrV_ta7fE4G"
      },
      "outputs": [],
      "source": [
        "# Set auto reload\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory\n",
        "%cd /content/drive/My Drive/Colab Notebooks/faceTracking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL3AgwfFgGyj",
        "outputId": "81cd5b8f-5c34-46d6-d013-805cc3f05a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/faceTracking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Config\n",
        "%config InlineBackend.figure_format = 'retina' #Retina display"
      ],
      "metadata": {
        "id": "wdXLx2hOgI4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise 'facenet' model for face detection\n",
        "faceConfig = 'deploy.prototxt.txt'\n",
        "faceModel = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "# Load 'facenet' model\n",
        "faceNet = cv2.dnn.readNet(\n",
        "    faceConfig,\n",
        "    faceModel\n",
        ")\n",
        "\n",
        "# Face tracking\n",
        "objectTracker = cv2.TrackerKCF_create() #Face tracking"
      ],
      "metadata": {
        "id": "-bX3bnP42J3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input video file\n",
        "cap = cv2.VideoCapture('objectTracking.mp4')\n",
        "w, h  = int(cap.get(3)), int(cap.get(4))\n",
        "\n",
        "# Output\n",
        "outVideo = cv2.VideoWriter(\n",
        "    'trackingResult.avi',\n",
        "    cv2.VideoWriter_fourcc(*'MJPG'), #With '.avi' format\n",
        "    30,\n",
        "    (w, h)\n",
        ")\n",
        "\n",
        "# Apply with video file\n",
        "tracking = False\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if ret == True:\n",
        "    (fh, fw) = frame.shape[:2]\n",
        "    if not tracking: #Tracking off\n",
        "      blob = cv2.dnn.blobFromImage(\n",
        "          frame,\n",
        "          1.0,\n",
        "          (300, 300),\n",
        "          (104.0, 177.0, 123.0)\n",
        "      )\n",
        "      faceNet.setInput(blob)\n",
        "      detections = faceNet.forward()\n",
        "      for i in range(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence < 0.5:\n",
        "          continue\n",
        "        box = detections[0, 0, i, 3:7] * np.array([fw, fh, fw, fh])\n",
        "        (startX, startY, endX, endY) = box.astype('int') #Return as the new area\n",
        "        (startX, startY) = (max(0, startX), max(0, startY))\n",
        "        (endX, endY) = (min(fw - 1, endX), min(fh - 1, endY))\n",
        "        cv2.rectangle(\n",
        "            frame,\n",
        "            (startX, startY),\n",
        "            (endX, endY),\n",
        "            (0, 0, 255),\n",
        "            2\n",
        "        )\n",
        "        if objectTracker.init(frame, (startX, startY, endX - startX, endY - startY)): #Minus to get location\n",
        "          tracking = True #Found face --> on object tracker\n",
        "    else: #Tracking on --> next iteration\n",
        "      check, box = objectTracker.update(frame)\n",
        "      if check: #Check track object\n",
        "        # New location\n",
        "        a = (int(box[0]), int(box[1])) #(x, y)\n",
        "        b = (int(box[0] + box[2]), int(box[1] + box[3])) #(x + w, y + h)\n",
        "        cv2.rectangle(\n",
        "            frame,\n",
        "            a,\n",
        "            b,\n",
        "            (0, 255, 0),\n",
        "            2\n",
        "        )\n",
        "      else:\n",
        "        tracking = False\n",
        "        objectTracker = cv2.TrackerKCF_create()\n",
        "    outVideo.write(frame)\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "id": "jVjzR-lXhr30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}